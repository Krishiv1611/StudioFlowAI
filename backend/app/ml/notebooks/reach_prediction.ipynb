{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import joblib\n",
                "import os\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
                "from sklearn.impute import SimpleImputer\n",
                "from sklearn.compose import ColumnTransformer\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_absolute_error, r2_score\n",
                "\n",
                "# --- 1. CONFIGURATION ---\n",
                "DATA_PATH = '../data/Social Media Engagement Dataset.csv'\n",
                "MODEL_DIR = '../models'\n",
                "MODEL_PATH = os.path.join(MODEL_DIR, 'reach_model.pkl')\n",
                "METADATA_PATH = os.path.join(MODEL_DIR, 'reach_metadata.pkl')\n",
                "\n",
                "RANDOM_SEED = 42\n",
                "os.makedirs(MODEL_DIR, exist_ok=True)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Loading Data...\n",
                        "Data loaded. Shape: (12000, 29)\n",
                        "WARNING: 'follower_count' column not found. Training without it.\n"
                    ]
                }
            ],
            "source": [
                "# --- 2. LOAD DATA ---\n",
                "print(\"Loading Data...\")\n",
                "try:\n",
                "    df = pd.read_csv(DATA_PATH)\n",
                "except FileNotFoundError:\n",
                "    # Fallback to absolute path\n",
                "    df = pd.read_csv(r'd:\\projects\\StudioFlowAI\\backend\\app\\ml\\data\\Social Media Engagement Dataset.csv')\n",
                "\n",
                "# --- 3. FEATURE ENGINEERING ---\n",
                "\n",
                "# Extract Time Features\n",
                "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
                "df['hour_of_day'] = df['timestamp'].dt.hour\n",
                "# Day of week is already in dataset as 'day_of_week'\n",
                "\n",
                "print(f\"Data loaded. Shape: {df.shape}\")\n",
                "\n",
                "# Check for follower_count\n",
                "has_followers = 'follower_count' in df.columns\n",
                "if has_followers:\n",
                "    print(\"Using 'follower_count' feature.\")\n",
                "else:\n",
                "    print(\"WARNING: 'follower_count' column not found. Training without it.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 4. PREPROCESSING ---\n",
                "categorical_features = ['platform', 'topic_category', 'day_of_week'] # time to post (day), topic\n",
                "numerical_features = ['hour_of_day'] # time to post (hour)\n",
                "\n",
                "if has_followers:\n",
                "    numerical_features.append('follower_count')\n",
                "\n",
                "target = 'impressions' # Reach\n",
                "\n",
                "X = df[categorical_features + numerical_features]\n",
                "y = df[target]\n",
                "\n",
                "# Split Data\n",
                "X_train, X_test, y_train, y_test = train_test_split(\n",
                "    X, y, test_size=0.2, random_state=RANDOM_SEED\n",
                ")\n",
                "\n",
                "# Preprocessing Pipeline\n",
                "numeric_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='median')),\n",
                "    ('scaler', StandardScaler())\n",
                "])\n",
                "\n",
                "categorical_transformer = Pipeline(steps=[\n",
                "    ('imputer', SimpleImputer(strategy='constant', fill_value='unknown')),\n",
                "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
                "])\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "    transformers=[\n",
                "        ('num', numeric_transformer, numerical_features),\n",
                "        ('cat', categorical_transformer, categorical_features)\n",
                "    ]\n",
                ")\n",
                "\n",
                "# Regression Model\n",
                "model = RandomForestRegressor(\n",
                "    n_estimators=200,\n",
                "    random_state=RANDOM_SEED,\n",
                "    n_jobs=-1\n",
                ")\n",
                "\n",
                "pipeline = Pipeline(steps=[\n",
                "    ('preprocessor', preprocessor),\n",
                "    ('regressor', model)\n",
                "])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Training Reach Prediction Model...\n",
                        "Mean Absolute Error: 26963.73\n",
                        "R2 Score: -0.2943\n"
                    ]
                }
            ],
            "source": [
                "# --- 5. TRAIN & EVALUATE ---\n",
                "print(\"Training Reach Prediction Model...\")\n",
                "pipeline.fit(X_train, y_train)\n",
                "\n",
                "y_pred = pipeline.predict(X_test)\n",
                "\n",
                "mae = mean_absolute_error(y_test, y_pred)\n",
                "r2 = r2_score(y_test, y_pred)\n",
                "\n",
                "print(f\"Mean Absolute Error: {mae:.2f}\")\n",
                "print(f\"R2 Score: {r2:.4f}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 6. SAVE ---\n",
                "print(f\"Saving model to {MODEL_PATH}...\")\n",
                "joblib.dump(pipeline, MODEL_PATH)\n",
                "\n",
                "metadata = {\n",
                "    'model_type': 'RandomForestRegressor',\n",
                "    'features': categorical_features + numerical_features,\n",
                "    'target': target\n",
                "}\n",
                "joblib.dump(metadata, METADATA_PATH)\n",
                "print(\"Model saved.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
